{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0.0, 0.0, 0.0], [-0.0, -0.0, -0.0]],\n",
       " [[-0.44039853898894116, 0.44039853898894116],\n",
       "  [-0.44039853898894116, 0.44039853898894116],\n",
       "  [-0.44039853898894116, 0.44039853898894116]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid_activation(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "\n",
    "def softmax_activation(x):\n",
    "    exp_x = [math.exp(i) for i in x]\n",
    "    sum_exp_x = sum(exp_x)\n",
    "    return [i / sum_exp_x for i in exp_x]\n",
    "\n",
    "\n",
    "def loss_(predictions: list, targets: list, clipping=1e-15):\n",
    "    # Clipping because inputs can't be 0\n",
    "    return -sum(\n",
    "        math.log(predictions[i] + clipping) * target[i] for i in range(len(targets))\n",
    "    )\n",
    "\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sig = sigmoid_activation(x)\n",
    "    return sig * (1 - sig)\n",
    "\n",
    "\n",
    "def softmax_derivative(x, index):\n",
    "    s = softmax_activation(x)\n",
    "    return s[index] * (1 - s[index])\n",
    "\n",
    "\n",
    "def forward_pass(inputs, weights_l1, bias_in, weights_l2, bias_out):\n",
    "    # Layer 1\n",
    "    nodes_l1 = [\n",
    "        sum(weights_l1[j][i] * inputs[j] for j in range(len(inputs))) + bias_in[i]\n",
    "        for i in range(len(bias_in))\n",
    "    ]\n",
    "    l1_sigmoid = [sigmoid_activation(x) for x in nodes_l1]\n",
    "\n",
    "    # Layer 2\n",
    "    nodes_l2 = [\n",
    "        sum(weights_l2[j][i] * l1_sigmoid[j] for j in range(len(l1_sigmoid)))\n",
    "        + bias_out[i]\n",
    "        for i in range(len(bias_out))\n",
    "    ]\n",
    "    predictions = softmax_activation(nodes_l2)\n",
    "    return nodes_l1, l1_sigmoid, nodes_l2, predictions\n",
    "\n",
    "\n",
    "def backward_pass(\n",
    "    inputs, target, nodes_l1, l1_sigmoid, nodes_l2, predictions, learning_rate=0.01\n",
    "):\n",
    "    # Error at output\n",
    "    delta_out = [\n",
    "        predictions[i] - target[i] for i in range(len(target))\n",
    "    ]  # Use len(target) here to avoid index error\n",
    "\n",
    "    # Error at hidden layer\n",
    "    delta_l2 = [\n",
    "        sum(delta_out[k] * weights_l2[i][k] for k in range(len(delta_out))) for i in range(len(weights_l2))\n",
    "    ]\n",
    "\n",
    "    delta_weights_2 = [\n",
    "        [delta_out[k] * l1_sigmoid[i] for k in range(len(delta_out))] for i in range(len(l1_sigmoid))\n",
    "    ]\n",
    "\n",
    "    delta_sigmoid = [\n",
    "        [delta_l2[k] * (l1_sigmoid[k] * (1 - l1_sigmoid[k])) for k in range(len(l1_sigmoid))]\n",
    "    ]\n",
    "\n",
    "    delta_l1 = [\n",
    "        sum(delta_sigmoid[0][k] * weights_l1[i][k] for k in range(len(delta_sigmoid[0]))) for i in range(len(weights_l1))\n",
    "    ]\n",
    "\n",
    "    delta_weights_1 = [\n",
    "        [inputs[i] * delta_sigmoid[0][k] for k in range(len(delta_sigmoid[0]))] for i in range(len(inputs))\n",
    "    ]\n",
    "\n",
    "    # Update weights and biases\n",
    "    # Layer 2 weights and biases\n",
    "    for i in range(len(weights_l2)):\n",
    "        for j in range(len(weights_l2[i])):\n",
    "            weights_l2[i][j] -= learning_rate * delta_weights_2[i][j]\n",
    "\n",
    "    for i in range(len(bias_out)):\n",
    "        bias_out[i] -= learning_rate * delta_out[i]\n",
    "\n",
    "    # Layer 1 weights and biases\n",
    "    for i in range(len(weights_l1)):\n",
    "        for j in range(len(weights_l1[i])):\n",
    "            weights_l1[i][j] -= learning_rate * delta_weights_1[i][j]\n",
    "\n",
    "    for i in range(len(bias_in)):\n",
    "        bias_in[i] -= learning_rate * delta_sigmoid[0][i]\n",
    "\n",
    "    return weights_l1, weights_l2, bias_out, bias_in, delta_weights_1, delta_weights_2\n",
    "\n",
    "\n",
    "# Running the training step\n",
    "inputs = [1, -1]\n",
    "weights_l1 = [[1, 1, 1], [-1, -1, -1]]\n",
    "bias_in = [0, 0, 0]\n",
    "weights_l2 = [[1, 1], [-1, -1], [-1, -1]]\n",
    "bias_out = [0, 0]\n",
    "target = [1, 0]\n",
    "\n",
    "nodes_l1, l1_sigmoid, nodes_l2, predictions = forward_pass(\n",
    "    inputs, weights_l1, bias_in, weights_l2, bias_out\n",
    ")\n",
    "loss = loss_(predictions, target)\n",
    "weights_l1, weights_l2, bias_out, bias_in, delta_weights_1, delta_weights_2 = backward_pass(inputs, target, nodes_l1, l1_sigmoid, nodes_l2, predictions)\n",
    "delta_weights_1, delta_weights_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
