{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bas/anaconda3/envs/musiclm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/bas/anaconda3/envs/musiclm/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "/home/bas/anaconda3/envs/musiclm/lib/python3.10/site-packages/transformers/models/encodec/modeling_encodec.py:120: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MusicgenForConditionalGeneration(\n",
       "  (text_encoder): T5EncoderModel(\n",
       "    (shared): Embedding(32128, 768)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 768)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 12)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-11): 11 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (audio_encoder): EncodecModel(\n",
       "    (encoder): EncodecEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): EncodecConv1d(\n",
       "          (conv): Conv1d(1, 64, kernel_size=(7,), stride=(1,))\n",
       "        )\n",
       "        (1): EncodecResnetBlock(\n",
       "          (block): ModuleList(\n",
       "            (0): ELU(alpha=1.0)\n",
       "            (1): EncodecConv1d(\n",
       "              (conv): Conv1d(64, 32, kernel_size=(3,), stride=(1,))\n",
       "            )\n",
       "            (2): ELU(alpha=1.0)\n",
       "            (3): EncodecConv1d(\n",
       "              (conv): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "        )\n",
       "        (2): ELU(alpha=1.0)\n",
       "        (3): EncodecConv1d(\n",
       "          (conv): Conv1d(64, 128, kernel_size=(8,), stride=(4,))\n",
       "        )\n",
       "        (4): EncodecResnetBlock(\n",
       "          (block): ModuleList(\n",
       "            (0): ELU(alpha=1.0)\n",
       "            (1): EncodecConv1d(\n",
       "              (conv): Conv1d(128, 64, kernel_size=(3,), stride=(1,))\n",
       "            )\n",
       "            (2): ELU(alpha=1.0)\n",
       "            (3): EncodecConv1d(\n",
       "              (conv): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "        )\n",
       "        (5): ELU(alpha=1.0)\n",
       "        (6): EncodecConv1d(\n",
       "          (conv): Conv1d(128, 256, kernel_size=(8,), stride=(4,))\n",
       "        )\n",
       "        (7): EncodecResnetBlock(\n",
       "          (block): ModuleList(\n",
       "            (0): ELU(alpha=1.0)\n",
       "            (1): EncodecConv1d(\n",
       "              (conv): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
       "            )\n",
       "            (2): ELU(alpha=1.0)\n",
       "            (3): EncodecConv1d(\n",
       "              (conv): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "        )\n",
       "        (8): ELU(alpha=1.0)\n",
       "        (9): EncodecConv1d(\n",
       "          (conv): Conv1d(256, 512, kernel_size=(10,), stride=(5,))\n",
       "        )\n",
       "        (10): EncodecResnetBlock(\n",
       "          (block): ModuleList(\n",
       "            (0): ELU(alpha=1.0)\n",
       "            (1): EncodecConv1d(\n",
       "              (conv): Conv1d(512, 256, kernel_size=(3,), stride=(1,))\n",
       "            )\n",
       "            (2): ELU(alpha=1.0)\n",
       "            (3): EncodecConv1d(\n",
       "              (conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "        )\n",
       "        (11): ELU(alpha=1.0)\n",
       "        (12): EncodecConv1d(\n",
       "          (conv): Conv1d(512, 1024, kernel_size=(16,), stride=(8,))\n",
       "        )\n",
       "        (13): EncodecLSTM(\n",
       "          (lstm): LSTM(1024, 1024, num_layers=2)\n",
       "        )\n",
       "        (14): ELU(alpha=1.0)\n",
       "        (15): EncodecConv1d(\n",
       "          (conv): Conv1d(1024, 128, kernel_size=(7,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): EncodecDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): EncodecConv1d(\n",
       "          (conv): Conv1d(128, 1024, kernel_size=(7,), stride=(1,))\n",
       "        )\n",
       "        (1): EncodecLSTM(\n",
       "          (lstm): LSTM(1024, 1024, num_layers=2)\n",
       "        )\n",
       "        (2): ELU(alpha=1.0)\n",
       "        (3): EncodecConvTranspose1d(\n",
       "          (conv): ConvTranspose1d(1024, 512, kernel_size=(16,), stride=(8,))\n",
       "        )\n",
       "        (4): EncodecResnetBlock(\n",
       "          (block): ModuleList(\n",
       "            (0): ELU(alpha=1.0)\n",
       "            (1): EncodecConv1d(\n",
       "              (conv): Conv1d(512, 256, kernel_size=(3,), stride=(1,))\n",
       "            )\n",
       "            (2): ELU(alpha=1.0)\n",
       "            (3): EncodecConv1d(\n",
       "              (conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "        )\n",
       "        (5): ELU(alpha=1.0)\n",
       "        (6): EncodecConvTranspose1d(\n",
       "          (conv): ConvTranspose1d(512, 256, kernel_size=(10,), stride=(5,))\n",
       "        )\n",
       "        (7): EncodecResnetBlock(\n",
       "          (block): ModuleList(\n",
       "            (0): ELU(alpha=1.0)\n",
       "            (1): EncodecConv1d(\n",
       "              (conv): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
       "            )\n",
       "            (2): ELU(alpha=1.0)\n",
       "            (3): EncodecConv1d(\n",
       "              (conv): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "        )\n",
       "        (8): ELU(alpha=1.0)\n",
       "        (9): EncodecConvTranspose1d(\n",
       "          (conv): ConvTranspose1d(256, 128, kernel_size=(8,), stride=(4,))\n",
       "        )\n",
       "        (10): EncodecResnetBlock(\n",
       "          (block): ModuleList(\n",
       "            (0): ELU(alpha=1.0)\n",
       "            (1): EncodecConv1d(\n",
       "              (conv): Conv1d(128, 64, kernel_size=(3,), stride=(1,))\n",
       "            )\n",
       "            (2): ELU(alpha=1.0)\n",
       "            (3): EncodecConv1d(\n",
       "              (conv): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "        )\n",
       "        (11): ELU(alpha=1.0)\n",
       "        (12): EncodecConvTranspose1d(\n",
       "          (conv): ConvTranspose1d(128, 64, kernel_size=(8,), stride=(4,))\n",
       "        )\n",
       "        (13): EncodecResnetBlock(\n",
       "          (block): ModuleList(\n",
       "            (0): ELU(alpha=1.0)\n",
       "            (1): EncodecConv1d(\n",
       "              (conv): Conv1d(64, 32, kernel_size=(3,), stride=(1,))\n",
       "            )\n",
       "            (2): ELU(alpha=1.0)\n",
       "            (3): EncodecConv1d(\n",
       "              (conv): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "        )\n",
       "        (14): ELU(alpha=1.0)\n",
       "        (15): EncodecConv1d(\n",
       "          (conv): Conv1d(64, 1, kernel_size=(7,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (quantizer): EncodecResidualVectorQuantizer(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x EncodecVectorQuantization(\n",
       "          (codebook): EncodecEuclideanCodebook()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): MusicgenForCausalLM(\n",
       "    (model): MusicgenModel(\n",
       "      (decoder): MusicgenDecoder(\n",
       "        (embed_tokens): ModuleList(\n",
       "          (0-7): 8 x Embedding(2049, 1024)\n",
       "        )\n",
       "        (embed_positions): MusicgenSinusoidalPositionalEmbedding()\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x MusicgenDecoderLayer(\n",
       "            (self_attn): MusicgenAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (activation_fn): GELUActivation()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): MusicgenAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (lm_heads): ModuleList(\n",
       "      (0-7): 8 x Linear(in_features=1024, out_features=2048, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (enc_to_dec_proj): Linear(in_features=768, out_features=1024, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/musicgen-stereo-small\")\n",
    "model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-stereo-small\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(\n",
    "    text=[\"80s pop track with bassy drums and synth\"],\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 2775,     7,  2783,  1463,    28,  7981,    63,  5253,     7,    11,\n",
       "         13353,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bas/anaconda3/envs/musiclm/lib/python3.10/site-packages/transformers/modeling_utils.py:4481: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Type 'Tuple[str, str]' cannot be traced. Only Tensors and (possibly nested) Lists, Dicts, and Tuples of Tensors can be traced",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/musiclm/lib/python3.10/site-packages/torch/jit/_trace.py:798\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 798\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    815\u001b[0m ):\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/musiclm/lib/python3.10/site-packages/torch/jit/_trace.py:1065\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1064\u001b[0m     example_inputs \u001b[38;5;241m=\u001b[39m make_tuple(example_inputs)\n\u001b[0;32m-> 1065\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_method_from_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar_lookup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m        \u001b[49m\u001b[43margument_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1076\u001b[0m check_trace_method \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_get_method(method_name)\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Type 'Tuple[str, str]' cannot be traced. Only Tensors and (possibly nested) Lists, Dicts, and Tuples of Tensors can be traced"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.jit.trace(\n",
    "    model,\n",
    "    inputs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musiclm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
