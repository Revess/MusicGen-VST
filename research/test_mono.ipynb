{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
    "import torch, os, glob, json, math\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import inspect\n",
    "\n",
    "folder = './musicgen-small'\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "cfg = 3\n",
    "temperature = 0.7\n",
    "top_k = 250\n",
    "top_p = 0.5\n",
    "max_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"facebook/musicgen-stereo-small\")\n",
    "inputs = processor(\n",
    "    text=[\"80s pop track with bassy drums and synth\"],\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=-1):\n",
    "    exp_x = np.exp(x - np.max(x, axis=axis, keepdims=True))  # Subtract max for numerical stability\n",
    "    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n",
    "\n",
    "# Step 2: Multinomial sampling from probabilities\n",
    "def multinomial(probs, num_samples=1):\n",
    "    # Create an empty array to hold sampled tokens\n",
    "    batch_size, seq_len, vocab_size = probs.shape\n",
    "    sampled_tokens = np.zeros((batch_size, seq_len), dtype=np.int32)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        for j in range(seq_len):\n",
    "            # Use np.random.choice to sample from the vocabulary based on probabilities\n",
    "            sampled_tokens[i, j] = np.random.multinomial(p=probs[i, j, :]).squeeze()\n",
    "    \n",
    "    return sampled_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(decoder_pattern_mask, ids):\n",
    "    seq_len = ids.shape[-1]\n",
    "    decoder_pattern_mask = decoder_pattern_mask[..., :seq_len]\n",
    "    return np.where(decoder_pattern_mask == -1, ids, decoder_pattern_mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2024-10-20 02:48:41.764537606 [W:onnxruntime:, execution_frame.cc:870 VerifyOutputSizes] Expected shape from model of {-1,16} does not match actual shape of {4,1} for output input_ids_edited\u001b[m\n"
     ]
    }
   ],
   "source": [
    "ort_session_mask = ort.InferenceSession(f\"{folder}/build_delay_pattern_mask.onnx\")\n",
    "\n",
    "_, decoder_pattern_mask = ort_session_mask.run(None, {\n",
    "    'input_ids': np.ones((4,16), dtype=np.int64) * -1,\n",
    "    'pad_token_id': np.array([2048], dtype=np.int64),\n",
    "    'max_length': np.array([max_len], dtype=np.int64),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\r"
     ]
    }
   ],
   "source": [
    "ort_session = ort.InferenceSession(f\"{folder}/text_encoder.onnx\")\n",
    "\n",
    "input_ids_np = inputs['input_ids'].detach().numpy()\n",
    "attention_mask_np = inputs['attention_mask'].detach().numpy()\n",
    "\n",
    "# Run the model\n",
    "ort_inputs = {\n",
    "    'input_ids': input_ids_np,\n",
    "    'attention_mask': attention_mask_np\n",
    "}\n",
    "encoded = ort_session.run(None, ort_inputs)[0]\n",
    "\n",
    "ort_session = ort.InferenceSession(f\"{folder}/decoder_model.onnx\")\n",
    "\n",
    "ort_inputs = {\n",
    "    'encoder_attention_mask': attention_mask_np, \n",
    "    'input_ids': np.ones((4,1), dtype=np.int64) * 2048, \n",
    "    'encoder_hidden_states': encoded, \n",
    "}\n",
    "\n",
    "for i in range(max_len - 1):\n",
    "    print(i, end='\\r')\n",
    "    ort_inputs['input_ids'] = apply_mask(decoder_pattern_mask, ort_inputs['input_ids'])\n",
    "    logits = ort_session.run(None, ort_inputs)[0]\n",
    "    logits = logits[:, -1, :][:, None]\n",
    "    # Apply temperature\n",
    "    if temperature > 0.0:\n",
    "        logits = logits / temperature\n",
    "\n",
    "    # Top K sampling\n",
    "    top_k_indices = np.argsort(logits)[:,:,-top_k:]\n",
    "    top_k_probs = np.take_along_axis(logits, top_k_indices, axis=-1)\n",
    "\n",
    "    # Softmax\n",
    "    top_k_probs = softmax(top_k_probs, axis=-1)\n",
    "\n",
    "    # Top\n",
    "    sorted_indices = np.argsort(top_k_probs, axis=-1)[..., ::-1]\n",
    "    sorted_probs = np.take_along_axis(top_k_probs, sorted_indices, axis=-1)\n",
    "\n",
    "    # Top p \n",
    "    if top_p < 1.0:\n",
    "        sorted_indices = np.argsort(top_k_probs, axis=-1)[..., ::-1]\n",
    "        sorted_probs = np.take_along_axis(top_k_probs, sorted_indices, axis=-1)\n",
    "\n",
    "        cumulative_probs = np.cumsum(sorted_probs, axis=-1)\n",
    "\n",
    "        sorted_indices_to_keep = cumulative_probs <= (1 - top_p)\n",
    "        sorted_indices_to_keep[..., 0] = True\n",
    "        filtered_probs = np.where(sorted_indices_to_keep, sorted_probs, 0)\n",
    "        filtered_probs = softmax(filtered_probs, axis=-1) # Chaning this to a different sampling could fix my life.\n",
    "        top_k_probs = filtered_probs\n",
    "\n",
    "    # Sample\n",
    "    logits = np.array([[top_k_indices[i, : , sorted_indices[i, :, np.random.multinomial(1, codebook, size=(1,)).argmax()]]] for i, codebook in enumerate(top_k_probs.squeeze())]).squeeze()[:, None]\n",
    "    # logits = np.argmax(logits, axis=-1)[:, -1]\n",
    "    ort_inputs['input_ids'] = np.concatenate((ort_inputs['input_ids'], logits), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ids = ort_inputs['input_ids']\n",
    "output_ids = apply_mask(decoder_pattern_mask, output_ids)\n",
    "output_ids = output_ids[output_ids != 2048].reshape(\n",
    "    1, 4, -1\n",
    ")\n",
    "\n",
    "# append the frame dimension back to the audio codes\n",
    "output_ids = output_ids[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 4, 0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = ort.InferenceSession(f\"{folder}/encodec_decode.onnx\")\n",
    "\n",
    "output_values = ort_session.run(None, {'audio_codes': output_ids})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "sampling_rate = 32000\n",
    "Audio(output_values[0], rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_values.shape[-1]/32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(max_len * 630) / 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_values.shape[-1] / max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_stereo_audio_from_array(audio_data):\n",
    "    \"\"\"\n",
    "    Plots the left and right channels of a stereo audio signal.\n",
    "\n",
    "    Parameters:\n",
    "    audio_data (numpy array): A 2D NumPy array with shape (channels, samples).\n",
    "    sample_rate (int): The sample rate of the audio signal.\n",
    "    \"\"\"\n",
    "    # Check if the audio is stereo (2 channels)\n",
    "    if audio_data.shape[0] == 2:\n",
    "        # Extract the left and right channels\n",
    "        left_channel = audio_data[0, :]\n",
    "        right_channel = audio_data[1, :]\n",
    "\n",
    "        # Create time axis in seconds\n",
    "        time = [i / 32000 for i in range(audio_data.shape[1])]\n",
    "\n",
    "        # Plot the left and right channels\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Plot left channel\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(time, left_channel, color='blue')\n",
    "        plt.title('Left Channel')\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Amplitude')\n",
    "\n",
    "        # Plot right channel\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(time, right_channel, color='green')\n",
    "        plt.title('Right Channel')\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Amplitude')\n",
    "\n",
    "        # Show the plot\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        left_channel = audio_data[0, :]\n",
    "\n",
    "        # Create time axis in seconds\n",
    "        time = [i / 32000 for i in range(audio_data.shape[1])]\n",
    "\n",
    "        # Plot the left and right channels\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Plot left channel\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(time, left_channel, color='blue')\n",
    "        plt.title('Left Channel')\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Amplitude')\n",
    "\n",
    "        # Show the plot\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stereo_audio_from_array(output_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "Name: encoder_attention_mask, Shape: [0, 0], Type: 7\n",
      "Name: input_ids, Shape: [0, 0], Type: 7\n",
      "Name: encoder_hidden_states, Shape: [0, 0, 768], Type: 1\n",
      "\n",
      "Outputs:\n",
      "Name: logits, Shape: [0, 0, 2048], Type: 1\n",
      "Name: present.0.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.0.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.0.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.0.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.1.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.1.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.1.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.1.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.2.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.2.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.2.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.2.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.3.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.3.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.3.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.3.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.4.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.4.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.4.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.4.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.5.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.5.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.5.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.5.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.6.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.6.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.6.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.6.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.7.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.7.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.7.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.7.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.8.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.8.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.8.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.8.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.9.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.9.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.9.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.9.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.10.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.10.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.10.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.10.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.11.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.11.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.11.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.11.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.12.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.12.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.12.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.12.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.13.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.13.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.13.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.13.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.14.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.14.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.14.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.14.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.15.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.15.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.15.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.15.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.16.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.16.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.16.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.16.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.17.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.17.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.17.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.17.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.18.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.18.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.18.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.18.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.19.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.19.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.19.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.19.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.20.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.20.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.20.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.20.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.21.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.21.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.21.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.21.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.22.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.22.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.22.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.22.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.23.decoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.23.decoder.value, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.23.encoder.key, Shape: [0, 16, 0, 64], Type: 1\n",
      "Name: present.23.encoder.value, Shape: [0, 16, 0, 64], Type: 1\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load(f\"musicgen-small/decoder_model.onnx\")\n",
    "\n",
    "# Check the model’s inputs\n",
    "input_all = onnx_model.graph.input\n",
    "output_all = onnx_model.graph.output\n",
    "\n",
    "print(\"Inputs:\")\n",
    "for input in input_all:\n",
    "    input_name = input.name\n",
    "    input_shape = [dim.dim_value for dim in input.type.tensor_type.shape.dim]\n",
    "    input_type = input.type.tensor_type.elem_type\n",
    "    print(f\"Name: {input_name}, Shape: {input_shape}, Type: {input_type}\")\n",
    "\n",
    "print(\"\\nOutputs:\")\n",
    "for output in output_all:\n",
    "    output_name = output.name\n",
    "    output_shape = [dim.dim_value for dim in output.type.tensor_type.shape.dim]\n",
    "    output_type = output.type.tensor_type.elem_type\n",
    "    print(f\"Name: {output_name}, Shape: {output_shape}, Type: {output_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "Name: audio_codes, Shape: [1, 0, 4, 0], Type: 7\n",
      "\n",
      "Outputs:\n",
      "Name: audio_values, Shape: [0, 1, 0], Type: 1\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load(f\"musicgen-small/encodec_decode.onnx\")\n",
    "\n",
    "# Check the model’s inputs\n",
    "input_all = onnx_model.graph.input\n",
    "output_all = onnx_model.graph.output\n",
    "\n",
    "print(\"Inputs:\")\n",
    "for input in input_all:\n",
    "    input_name = input.name\n",
    "    input_shape = [dim.dim_value for dim in input.type.tensor_type.shape.dim]\n",
    "    input_type = input.type.tensor_type.elem_type\n",
    "    print(f\"Name: {input_name}, Shape: {input_shape}, Type: {input_type}\")\n",
    "\n",
    "print(\"\\nOutputs:\")\n",
    "for output in output_all:\n",
    "    output_name = output.name\n",
    "    output_shape = [dim.dim_value for dim in output.type.tensor_type.shape.dim]\n",
    "    output_type = output.type.tensor_type.elem_type\n",
    "    print(f\"Name: {output_name}, Shape: {output_shape}, Type: {output_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "255\n",
      "510\n",
      "765\n"
     ]
    }
   ],
   "source": [
    "from math import floor\n",
    "\n",
    "# (codebook_step * max_len) + (step - 1)\n",
    "max_len = 256\n",
    "step = 1\n",
    "for i in range(4*step):\n",
    "    codebook = floor(i / step)\n",
    "    print((codebook * (max_len-1)) + (i % step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "255\n",
      "510\n",
      "765\n",
      "0\n",
      "1\n",
      "255\n",
      "256\n",
      "510\n",
      "511\n",
      "765\n",
      "766\n",
      "0\n",
      "1\n",
      "2\n",
      "255\n",
      "256\n",
      "257\n",
      "510\n",
      "511\n",
      "512\n",
      "765\n",
      "766\n",
      "767\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n"
     ]
    }
   ],
   "source": [
    "from math import floor\n",
    "\n",
    "max_len = 256\n",
    "\n",
    "for step in range(8):\n",
    "    # (codebook_step * max_len) + (step - 1)\n",
    "    for i in range(4*step):\n",
    "        codebook = floor(i / step)\n",
    "        print((codebook * (max_len-1)) + (i % step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "257\n",
      "513\n",
      "769\n"
     ]
    }
   ],
   "source": [
    "from math import floor\n",
    "\n",
    "# (codebook_step * max_len) + (step - 1)\n",
    "max_len = 256\n",
    "step = 1\n",
    "for codebook in range(4):\n",
    "    print((codebook * max_len) + step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ofstream Coutfile(\"./C_output.txt\");\n",
    "\n",
    "#     if (Coutfile.is_open()) {\n",
    "#         // Write each element of the vector to the file, one element per line\n",
    "#         for (const auto& value : decoder_pattern_mask) {\n",
    "#             Coutfile << value << std::endl;  // Each value on a new line\n",
    "#         }\n",
    "#         Coutfile.close();  // Close the file\n",
    "#     } else {\n",
    "#         std::cerr << \"Unable to open file\" << std::endl;\n",
    "#     }\n",
    "\n",
    "#     return input_sentences[0];"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musiclm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
